{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping2D, Convolution2D\n",
    "from keras.layers import Dense, Dropout, Flatten, Lambda, ELU, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=[]\n",
    "\n",
    "with open('/home/osaid_b25/projects/driving_log.csv') as csvfile:\n",
    "    reader=csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "           lines.append(line)\n",
    "images = []\n",
    "measurements = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in the images using the csv file\n",
    "lines=lines[1:len(lines)]\n",
    "for line in lines:\n",
    "    #looping for all the left center and right camera images\n",
    "    for i in range(3):\n",
    "        source_path=line[i]\n",
    "        filename= source_path.split('\\\\')[-1]\n",
    "        current_path='/home/osaid_b25/projects/IMG/'+filename\n",
    "        #print(current_path)\n",
    "        image=cv2.imread(current_path)\n",
    "        #print(image)\n",
    "        images.append(image)\n",
    "    measurment= float(line[3])\n",
    "    measurements.append(measurment)\n",
    "    #adding and subtracting 0.27 steering for adjusting for the left and right camera images\n",
    "    measurements.append(measurment+0.27)\n",
    "    measurements.append(measurment-0.27)\n",
    "    \n",
    "    \n",
    "X_train =np.array(images)\n",
    "y_train =np.array(measurements)\n",
    "#print (measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model= Sequential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/osaid_b25/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (5, 5), activation=\"elu\", strides=(2, 2))`\n",
      "  \"\"\"\n",
      "/home/osaid_b25/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(36, (5, 5), activation=\"elu\", strides=(2, 2))`\n",
      "  \n",
      "/home/osaid_b25/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), activation=\"elu\", strides=(2, 2))`\n",
      "  import sys\n",
      "/home/osaid_b25/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"elu\")`\n",
      "  \n",
      "/home/osaid_b25/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"elu\")`\n",
      "  if __name__ == '__main__':\n",
      "/home/osaid_b25/miniconda3/lib/python3.6/site-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8373 samples, validate on 2094 samples\n",
      "Epoch 1/25\n",
      "8373/8373 [==============================] - 115s 14ms/step - loss: 0.0533 - val_loss: 0.0646\n",
      "Epoch 2/25\n",
      "8373/8373 [==============================] - 117s 14ms/step - loss: 0.0417 - val_loss: 0.0625\n",
      "Epoch 3/25\n",
      "8373/8373 [==============================] - 110s 13ms/step - loss: 0.0399 - val_loss: 0.0691\n",
      "Epoch 4/25\n",
      "8373/8373 [==============================] - 114s 14ms/step - loss: 0.0372 - val_loss: 0.0616\n",
      "Epoch 5/25\n",
      "8373/8373 [==============================] - 109s 13ms/step - loss: 0.0345 - val_loss: 0.0706\n",
      "Epoch 6/25\n",
      "8373/8373 [==============================] - 112s 13ms/step - loss: 0.0314 - val_loss: 0.0720\n",
      "Epoch 7/25\n",
      "8373/8373 [==============================] - 109s 13ms/step - loss: 0.0299 - val_loss: 0.0773\n",
      "Epoch 8/25\n",
      "8373/8373 [==============================] - 113s 13ms/step - loss: 0.0286 - val_loss: 0.0767\n",
      "Epoch 9/25\n",
      "8373/8373 [==============================] - 113s 13ms/step - loss: 0.0252 - val_loss: 0.0810\n",
      "Epoch 10/25\n",
      "8373/8373 [==============================] - 110s 13ms/step - loss: 0.0245 - val_loss: 0.0782\n",
      "Epoch 11/25\n",
      "8373/8373 [==============================] - 116s 14ms/step - loss: 0.0231 - val_loss: 0.0828\n",
      "Epoch 12/25\n",
      "8373/8373 [==============================] - 108s 13ms/step - loss: 0.0214 - val_loss: 0.0966\n",
      "Epoch 13/25\n",
      "8373/8373 [==============================] - 114s 14ms/step - loss: 0.0215 - val_loss: 0.0796\n",
      "Epoch 14/25\n",
      "8373/8373 [==============================] - 109s 13ms/step - loss: 0.0197 - val_loss: 0.0761\n",
      "Epoch 15/25\n",
      "8373/8373 [==============================] - 114s 14ms/step - loss: 0.0190 - val_loss: 0.0756\n",
      "Epoch 16/25\n",
      "8373/8373 [==============================] - 113s 14ms/step - loss: 0.0186 - val_loss: 0.0870\n",
      "Epoch 17/25\n",
      "8373/8373 [==============================] - 109s 13ms/step - loss: 0.0165 - val_loss: 0.0868\n",
      "Epoch 18/25\n",
      "8373/8373 [==============================] - 117s 14ms/step - loss: 0.0154 - val_loss: 0.0963\n",
      "Epoch 19/25\n",
      "8373/8373 [==============================] - 108s 13ms/step - loss: 0.0154 - val_loss: 0.0845\n",
      "Epoch 20/25\n",
      "8373/8373 [==============================] - 106s 13ms/step - loss: 0.0151 - val_loss: 0.0915\n",
      "Epoch 21/25\n",
      "8373/8373 [==============================] - 114s 14ms/step - loss: 0.0135 - val_loss: 0.0868\n",
      "Epoch 22/25\n",
      "8373/8373 [==============================] - 111s 13ms/step - loss: 0.0131 - val_loss: 0.0907\n",
      "Epoch 23/25\n",
      "8373/8373 [==============================] - 109s 13ms/step - loss: 0.0117 - val_loss: 0.0855\n",
      "Epoch 24/25\n",
      "8373/8373 [==============================] - 116s 14ms/step - loss: 0.0114 - val_loss: 0.0959\n",
      "Epoch 25/25\n",
      "8373/8373 [==============================] - 111s 13ms/step - loss: 0.0110 - val_loss: 0.0871\n"
     ]
    }
   ],
   "source": [
    "#Lambda layer for normalizing the training data\n",
    "model.add(Lambda(lambda x: x/255.0-0.5,input_shape=(160,320,3)))\n",
    "#Cropping the images to exclude the part that is not required\n",
    "model.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "model.add(Convolution2D(24,5,5, subsample=(2,2), activation=\"elu\"))\n",
    "model.add(Convolution2D(36,5,5, subsample=(2,2), activation=\"elu\"))\n",
    "model.add(Convolution2D(48,5,5, subsample=(2,2), activation=\"elu\"))\n",
    "model.add(Convolution2D(64,3,3, activation=\"elu\"))\n",
    "model.add(Convolution2D(64,3,3, activation=\"elu\"))\n",
    "#addded droput layer to prevent overfitting\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100))\n",
    "#model.add(ELU())\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(50))\n",
    "#model.add(ELU())\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10))\n",
    "#model.add(ELU())\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "#Using the adam optimizer and mean squared error as the loss function\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(X_train, y_train, validation_split=0.20, shuffle=True, nb_epoch = 25)\n",
    "\n",
    "model.save('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
